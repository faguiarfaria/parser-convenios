{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5b1e5af",
   "metadata": {},
   "source": [
    "# üìÑ Parser MetLife - Google Colab\n",
    "\n",
    "Este notebook executa o parser de demonstrativos da MetLife, extraindo dados de GTOs e exportando em formato Excel.\n",
    "\n",
    "‚ö†Ô∏è **Importante**: Este notebook deve ser usado com arquivos no formato PDF gerados pela MetLife, com o layout esperado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573767b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß PASSO 1 - Instalar bibliotecas necess√°rias\n",
    "!pip install pdfplumber openpyxl pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f583ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÇ PASSO 2 - Upload do arquivo PDF do relat√≥rio MetLife\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ba7146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß† PASSO 3 - Fun√ß√£o de extra√ß√£o de dados do relat√≥rio MetLife\n",
    "import pdfplumber  # Biblioteca para ler e extrair texto de arquivos PDF\n",
    "import pandas as pd  # Biblioteca para manipula√ß√£o de dados em tabelas (DataFrames)\n",
    "import re  # Biblioteca para trabalhar com express√µes regulares (padr√µes de texto)\n",
    "import sys  # Biblioteca para ler argumentos passados via linha de comando\n",
    "\n",
    "# Fun√ß√£o principal que extrai os dados do PDF\n",
    "def extrair_dados_metlife(pdf_path):\n",
    "    resultados = []  # Lista onde vamos armazenar os dados extra√≠dos\n",
    "\n",
    "    # Junta o texto de todas as p√°ginas do PDF em uma √∫nica string\n",
    "    texto_completo = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            texto = page.extract_text()\n",
    "            if texto:\n",
    "                texto_completo += texto + \"\\n\"\n",
    "\n",
    "    # Divide o texto em linhas para an√°lise linha a linha\n",
    "    linhas = texto_completo.split('\\n')\n",
    "\n",
    "    # Fun√ß√£o auxiliar que converte texto para n√∫mero decimal (float)\n",
    "    def to_float(valor):\n",
    "        try:\n",
    "            # Remove os pontos (separador de milhar) e troca a v√≠rgula decimal por ponto\n",
    "            return float(valor.replace('.', '').replace(',', '.').strip())\n",
    "        except:\n",
    "            return 0.0\n",
    "\n",
    "    i = 0  # √çndice da linha atual\n",
    "    data_pgto = \"\"\n",
    "   \n",
    "    while i < len(linhas):\n",
    "\n",
    "        # Captura a data de pagamento\n",
    "        if linhas[i].strip() == \"10 - Data do Pagamento 11 - Banco 12 - Ag√™ncia 13 - Conta\":\n",
    "\n",
    "             # Verifica se h√° pelo menos 1 linhas seguinte dispon√≠vel, pois data sempre est√° na linha abaixo\n",
    "            if i + 1 < len(linhas):\n",
    "                linha_data_pgto = linhas[i + 1].strip()\n",
    "                data_pgto_match = re.search(r\"\\d{2}/\\d{2}/\\d{4}\", linha_data_pgto)\n",
    "                data_pgto = data_pgto_match.group(0) if data_pgto_match else data_pgto\n",
    "\n",
    "        # In√≠cio de uma nova GTO √© identificado por esta string\n",
    "        if linhas[i].strip() == \"Dados da Guia\":\n",
    "\n",
    "                # Verifica se h√° pelo menos 4 linhas seguintes dispon√≠veis\n",
    "                if i + 4 < len(linhas):\n",
    "                    # Segunda linha abaixo da \"Dados da Guia\" ‚Üí cont√©m o c√≥digo da GTO\n",
    "                    linha_gto = linhas[i + 2].strip()\n",
    "                    gto_match = re.match(r\"\\b\\d{9}\\b\", linha_gto)\n",
    "                    gto = gto_match.group(0) if gto_match else \"\"\n",
    "\n",
    "                    # Quarta linha abaixo da \"Dados da Guia\" ‚Üí c√≥digo do paciente + nome\n",
    "                    linha_paciente = linhas[i + 4].strip()\n",
    "                    paciente_match = re.match(r\"\\b\\d{14}\\b\", linha_paciente)\n",
    "                    cod_paciente = paciente_match.group(0) if paciente_match else \"\"\n",
    "\n",
    "                    # Nome do paciente logo ap√≥s o c√≥digo de 14 d√≠gitos\n",
    "                    nome_social = \"\"\n",
    "                    if cod_paciente:\n",
    "                        tokens = linha_paciente.split()\n",
    "                        try:\n",
    "                            idx = tokens.index(cod_paciente) + 1\n",
    "                            while idx < len(tokens) and tokens[idx].isupper():\n",
    "                                nome_social += tokens[idx] + \" \"\n",
    "                                idx += 1\n",
    "                            nome_social = nome_social.strip()\n",
    "                        except ValueError:\n",
    "                            pass\n",
    "\n",
    "                    # Captura o texto da glosa (justificativa)\n",
    "                    glosa = \"\"  # Metlife n√£o apresenta glosa nos seus demonstrativos\n",
    "\n",
    "                    # Procura os valores financeiros da GTO\n",
    "                    valor_info = valor_glosa = valor_pago = \"\"\n",
    "                    for j in range(i + 1, min(i + 30, len(linhas))):\n",
    "                        if \"Total da Guia\" in linhas[j]:\n",
    "                            if j + 2 < len(linhas):\n",
    "                                tot_valores = linhas[j + 2].strip().split()\n",
    "                                if len(tot_valores) >= 5:\n",
    "                                    valor_info = tot_valores[0]\n",
    "                                    valor_glosa = tot_valores[2]\n",
    "                                    valor_pago = tot_valores[4]\n",
    "                            break\n",
    "\n",
    "                    # Adiciona os dados extra√≠dos ao resultado\n",
    "                    resultados.append({\n",
    "                        \"Data\": data_pgto,\n",
    "                        \"Conv√™nio\": \"MetLife\",\n",
    "                        \"GTO\": gto,\n",
    "                        \"C√≥digo do Paciente\": cod_paciente,\n",
    "                        \"Nome Social do Paciente\": nome_social,\n",
    "                        \"Glosas\": glosa,\n",
    "                        \"Valor informado\": to_float(valor_info),\n",
    "                        \"Valor glosado\": to_float(valor_glosa),\n",
    "                        \"Valor pago\": to_float(valor_pago)\n",
    "                    })\n",
    "\n",
    "        # Avan√ßa sempre uma linha ap√≥s cada itera√ß√£o\n",
    "        i += 1\n",
    "\n",
    "    # Converte os dados para um DataFrame do pandas\n",
    "    return pd.DataFrame(resultados)\n",
    "\n",
    "\n",
    "# Executa o script apenas se for rodado diretamente (n√£o importado como m√≥dulo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0452df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ñ∂Ô∏è PASSO 4 - Executar parser e exportar para Excel\n",
    "import os\n",
    "\n",
    "pdf_path = list(uploaded.keys())[0]\n",
    "df = extrair_dados_metlife(pdf_path)\n",
    "\n",
    "saida = \"procedimentos_metlife.xlsx\"\n",
    "df.to_excel(saida, index=False, engine='openpyxl')\n",
    "print(f\"‚úÖ Arquivo gerado: {saida}\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf11d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì• PASSO 5 - Download do arquivo gerado\n",
    "from google.colab import files\n",
    "files.download(saida)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
