{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b77520d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìå Instala as depend√™ncias necess√°rias\n",
    "!pip install pdfplumber openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaabcc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÅ Faz upload do PDF manualmente (ou use do Google Drive)\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc893d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÑ Exibe os arquivos enviados\n",
    "import os\n",
    "for fn in uploaded.keys():\n",
    "    print(f\"Arquivo enviado: {fn}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97e2cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîé Fun√ß√£o principal para extra√ß√£o dos dados\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extrair_dados_unimed_corrigido(pdf_path):\n",
    "    resultados = []  # Lista onde vamos armazenar os dados extra√≠dos\n",
    "\n",
    "    # Junta o texto de todas as p√°ginas do PDF em uma √∫nica string\n",
    "    texto_completo = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            texto = page.extract_text()\n",
    "            if texto:\n",
    "                texto_completo += texto + \"\\n\"\n",
    "\n",
    "    # Divide o texto em linhas para an√°lise linha a linha\n",
    "    linhas = texto_completo.split('\\n')\n",
    "\n",
    "    # Fun√ß√£o auxiliar que converte texto para n√∫mero decimal (float)\n",
    "    def to_float(valor):\n",
    "        try:\n",
    "            return float(valor.strip())  # Usa ponto como separador decimal (formato americano)\n",
    "        except:\n",
    "            return 0.0\n",
    "\n",
    "    i = 0  # √çndice da linha atual\n",
    "    while i < len(linhas):\n",
    "        # In√≠cio de uma nova GTO √© identificado por esta string\n",
    "        if linhas[i].strip().startswith(\"Dados do Pagamento\"):\n",
    "\n",
    "            # Verifica se h√° pelo menos duas linhas seguintes dispon√≠veis\n",
    "            if i + 2 < len(linhas):\n",
    "                cabecalho = linhas[i + 1]  # N√£o usado no c√≥digo, mas mantido como poss√≠vel refer√™ncia\n",
    "                valores = linhas[i + 2]  # Cont√©m informa√ß√µes principais: GTO, c√≥digo do paciente, nome e data\n",
    "                val_split = valores.split()  # Divide a linha em palavras (tokens)\n",
    "\n",
    "                # Busca dois n√∫meros longos consecutivos: GTO e c√≥digo do paciente\n",
    "                num_grandes_idx = [idx for idx, val in enumerate(val_split) if re.fullmatch(r\"\\d{8,12}\", val)]\n",
    "                gto = val_split[num_grandes_idx[0]] if len(num_grandes_idx) > 0 else \"\"\n",
    "                cod_carteira = val_split[num_grandes_idx[1]] if len(num_grandes_idx) > 1 else \"\"\n",
    "\n",
    "                # Extrai nome social (logo ap√≥s o c√≥digo do paciente)\n",
    "                nome_social = \"\"\n",
    "                if len(num_grandes_idx) > 1:\n",
    "                    idx_nome_inicio = num_grandes_idx[1] + 1\n",
    "                    nome_tokens = []\n",
    "                    token_max = 10  # limite de palavras para evitar erros\n",
    "                    for idz, token in enumerate(val_split[idx_nome_inicio:]):\n",
    "                        if token.isupper() and not re.fullmatch(r\"\\d{8,12}\", token):\n",
    "                            if nome_tokens and token == nome_tokens[0]:\n",
    "                                break  # Evita repeti√ß√£o duplicada do nome\n",
    "                            nome_tokens.append(token)\n",
    "                            if idz + 1 >= token_max:\n",
    "                                break\n",
    "                        else:\n",
    "                            break\n",
    "                    nome_social = \" \".join(nome_tokens)\n",
    "\n",
    "                # Captura a data de pagamento logo ap√≥s a string \"Dt. Pagto.\"\n",
    "                try:\n",
    "                    dt_pgto_idx = val_split.index(\"Dt.\") if \"Dt.\" in val_split else val_split.index(\"Dt. Pagto.\")\n",
    "                    data_pgto = val_split[dt_pgto_idx + 2] if val_split[dt_pgto_idx + 1] == \"Pagto.\" else val_split[dt_pgto_idx + 1]\n",
    "                except ValueError:\n",
    "                    data_pgto = \"\"\n",
    "\n",
    "            # Se o bloco n√£o tiver as duas linhas seguintes, ignora\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            # Captura o texto da glosa (justificativa)\n",
    "            glosa = \"\"\n",
    "            for j in range(i, min(i + 20, len(linhas))):\n",
    "                if linhas[j].strip().startswith(\"27 - Observa√ß√£o / Justificativa\"):\n",
    "                    if j + 1 < len(linhas):\n",
    "                        glosa_texto = linhas[j + 1].strip()\n",
    "                        if glosa_texto.startswith(\"Total de Pontos:\"):\n",
    "                            glosa = \"\"  # Ignora glosas irrelevantes\n",
    "                            break\n",
    "                        glosa = glosa_texto\n",
    "                    break  # Finaliza a leitura da glosa\n",
    "\n",
    "            # Procura os valores financeiros da GTO\n",
    "            valor_info = valor_glosa = valor_pago = \"\"\n",
    "            for j in range(i + 1, min(i + 15, len(linhas))):\n",
    "                if \"28 - Valor Total Informado Guia\" in linhas[j]:\n",
    "                    if j + 1 < len(linhas):\n",
    "                        tot_valores = linhas[j + 1].strip().split()\n",
    "                        if len(tot_valores) >= 5:\n",
    "                            valor_info = tot_valores[0]\n",
    "                            valor_glosa = tot_valores[2]\n",
    "                            valor_pago = tot_valores[4]\n",
    "                    break\n",
    "\n",
    "            # Adiciona os dados extra√≠dos ao resultado\n",
    "            resultados.append({\n",
    "                \"Data\": data_pgto,\n",
    "                \"Conv√™nio\": \"Rede Unna\",\n",
    "                \"GTO\": gto,\n",
    "                \"C√≥digo do Paciente\": cod_carteira,\n",
    "                \"Nome Social do Paciente\": nome_social,\n",
    "                \"Glosas\": glosa,\n",
    "                \"Valor informado\": to_float(valor_info),\n",
    "                \"Valor glosado\": to_float(valor_glosa),\n",
    "                \"Valor pago\": to_float(valor_pago)\n",
    "            })\n",
    "\n",
    "        # Avan√ßa sempre uma linha ap√≥s cada itera√ß√£o\n",
    "        i += 1\n",
    "\n",
    "    # Converte os dados para um DataFrame do pandas\n",
    "    return pd.DataFrame(resultados)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d1c93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Executa a extra√ß√£o e exibe os dados\n",
    "nome_pdf = list(uploaded.keys())[0]\n",
    "df = extrair_dados_unimed_corrigido(nome_pdf)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8befab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üíæ Exporta o DataFrame para Excel\n",
    "saida = \"procedimentos_redeunna.xlsx\"\n",
    "df.to_excel(saida, index=False)\n",
    "files.download(saida)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}